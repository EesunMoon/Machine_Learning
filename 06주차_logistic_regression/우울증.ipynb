{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"/kaggle/input/2021-ml-p8/train_Y.csv\n/kaggle/input/2021-ml-p8/train_X.csv\n/kaggle/input/2021-ml-p8/test_X.csv\n/kaggle/input/2021-ml-p8/sample_submit.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"x_data = pd.read_csv('/kaggle/input/2021-ml-p8/train_X.csv')\ny_data = pd.read_csv('/kaggle/input/2021-ml-p8/train_Y.csv')\ntest_data = pd.read_csv('/kaggle/input/2021-ml-p8/test_X.csv')\nsubmit = pd.read_csv('/kaggle/input/2021-ml-p8/sample_submit.csv')\n\nprint(x_data.head())\nprint(y_data.head())\nprint(x_data.shape)\nprint(y_data.shape)","metadata":{"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"   sleep_time_mean  sleep_time_std  sleep_time_min  sleep_time_25  \\\n0         6.250000        0.689202             5.0          6.125   \n1         6.418182        1.169693             3.0          6.000   \n2         7.034483        1.127262             5.5          6.500   \n3         6.453846        1.070642             3.0          6.000   \n4         5.902439        1.817345             3.5          4.500   \n\n   sleep_time_50  sleep_time_75  sleep_time_max  sleep_quality_mean  \\\n0            6.5           6.50             7.0            3.500000   \n1            6.5           6.75             9.5            3.345455   \n2            6.5           8.00            11.0            3.862069   \n3            6.5           7.00             9.0            3.061538   \n4            5.5           7.00            10.0            2.975610   \n\n   sleep_quality_std  sleep_quality_min  sleep_quality_25  sleep_quality_50  \\\n0           0.836660                2.0              3.25               4.0   \n1           0.672700                1.0              3.00               3.0   \n2           0.347839                3.0              4.00               4.0   \n3           0.768052                1.0              3.00               3.0   \n4           0.961452                1.0              2.00               3.0   \n\n   sleep_quality_75  sleep_quality_max  \n0               4.0                4.0  \n1               4.0                4.0  \n2               4.0                4.0  \n3               4.0                4.0  \n4               4.0                4.0  \n   label\n0      0\n1      0\n2      0\n3      1\n4      0\n(23, 14)\n(23, 1)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### oversampling 해보기","metadata":{}},{"cell_type":"code","source":"# oversampling\nfrom imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=123)\nx_sm, y_sm = sm.fit_resample(x_data, y_data)\nprint(x_sm.shape)\nprint(y_sm.shape)","metadata":{"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"(34, 14)\n(34, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"# train , validation split\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(x_sm, y_sm, test_size = 0.3, random_state = 123 , stratify = y_sm)\nprint(x_train.shape)\nprint(x_val.shape)\nprint(y_train.shape)\nprint(y_val.shape)","metadata":{"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"(23, 14)\n(11, 14)\n(23, 1)\n(11, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"# logistic regression\nfrom sklearn.linear_model import LogisticRegression\n\n# 아무것도 설정 안 한 상태\nlg = LogisticRegression()\n\nl2_100 = LogisticRegression(penalty='l2', C=100.0, solver='saga', max_iter=400)\nl2_10 = LogisticRegression(penalty = 'l2', C = 10.0, solver = 'saga', max_iter=500)\nl2_1 = LogisticRegression(penalty = 'l2', C = 1.0, solver = 'saga', max_iter=500)\nl2_01 = LogisticRegression(penalty = 'l2', C = 0.1, solver = 'saga', max_iter=500)\nl2_001 = LogisticRegression(penalty = 'l2', C = 0.01, solver = 'saga', max_iter=500)\n\n# l1_100 = LogisticRegression(penalty='l1', C=100.0, solver='saga', max_iter=500)\n# l1_10 = LogisticRegression(penalty = 'l1', C = 10.0, solver = 'saga', max_iter=500)\n# l1_1 = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'saga', max_iter=500)\n# l1_01 = LogisticRegression(penalty = 'l1', C = 0.1, solver = 'saga', max_iter=500)","metadata":{"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"lg.fit(x_train, y_train.values.ravel())\nprint(lg.score(x_val, y_val))\n\nl2_100.fit(x_train, y_train.values.ravel())\nprint(l2_100.score(x_val, y_val))\nl2_10.fit(x_train, y_train.values.ravel())\nprint(l2_10.score(x_val, y_val))\nl2_1.fit(x_train, y_train.values.ravel())\nprint(l2_1.score(x_val, y_val))\nl2_01.fit(x_train, y_train.values.ravel())\nprint(l2_01.score(x_val, y_val))\nl2_001.fit(x_train, y_train.values.ravel())\nprint(l2_001.score(x_val, y_val))\n\n# l1_100.fit(x_train, y_train.values.ravel())\n# print(l1_100.score(x_val, y_val))\n# l1_10.fit(x_train, y_train.values.ravel())\n# print(l1_10.score(x_val, y_val))\n# l1_1.fit(x_train, y_train.values.ravel())\n# print(l1_1.score(x_val, y_val))\n# l1_01.fit(x_train, y_train.values.ravel())\n# print(l1_01.score(x_val, y_val))","metadata":{"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"0.7272727272727273\n0.9090909090909091\n0.9090909090909091\n0.9090909090909091\n0.8181818181818182\n0.5454545454545454\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\npred = lg.predict(x_val)\nprint(accuracy_score(y_val, pred))\n\npred = l2_100.predict(x_val)\nprint(accuracy_score(y_val, pred))\npred = l2_10.predict(x_val)\nprint(accuracy_score(y_val, pred))\npred = l2_1.predict(x_val)\nprint(accuracy_score(y_val, pred))\npred = l2_01.predict(x_val)\nprint(accuracy_score(y_val, pred))\n\n# pred = l1_100.predict(x_val)\n# print(accuracy_score(y_val, pred))\n# pred = l1_10.predict(x_val)\n# print(accuracy_score(y_val, pred))\n# pred = l1_1.predict(x_val)\n# print(accuracy_score(y_val, pred))\n# pred = l1_01.predict(x_val)\n# print(accuracy_score(y_val, pred))","metadata":{"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"0.7272727272727273\n0.9090909090909091\n0.9090909090909091\n0.9090909090909091\n0.8181818181818182\n","output_type":"stream"}]},{"cell_type":"code","source":"# 표준화\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train_sc = sc.fit_transform(x_train)\nx_val_sc = sc.transform(x_val)\n\n# 정규화\nfrom sklearn.preprocessing import MinMaxScaler\nmm = MinMaxScaler()\nx_train_mm = mm.fit_transform(x_train)\nx_val_mm = mm.transform(x_val)","metadata":{"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# sc\nlg.fit(x_train_sc, y_train.values.ravel()) #0.8571428571428571\nprint(lg.score(x_val_sc, y_val))\n\nl2_100.fit(x_train_sc, y_train.values.ravel())\nprint(l2_100.score(x_val_sc, y_val))\nl2_10.fit(x_train_sc, y_train.values.ravel())\nprint(l2_10.score(x_val_sc, y_val))\nl2_1.fit(x_train_sc, y_train.values.ravel())\nprint(l2_1.score(x_val_sc, y_val))\nl2_01.fit(x_train_sc, y_train.values.ravel())\nprint(l2_01.score(x_val_sc, y_val))\n\n# l1_100.fit(x_train_sc, y_train.values.ravel())\n# print(l1_100.score(x_val_sc, y_val))\n# l1_10.fit(x_train_sc, y_train.values.ravel())\n# print(l1_10.score(x_val_sc, y_val))\n# l1_1.fit(x_train_sc, y_train.values.ravel()) #0.8571428571428571\n# print(l1_1.score(x_val_sc, y_val))\n# l1_01.fit(x_train_sc, y_train.values.ravel())\n# print(l1_01.score(x_val_sc, y_val))","metadata":{"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"0.8181818181818182\n0.6363636363636364\n0.5454545454545454\n0.8181818181818182\n0.6363636363636364\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n","output_type":"stream"}]},{"cell_type":"code","source":"# mm\nlg.fit(x_train_mm, y_train.values.ravel())\nprint(lg.score(x_val_mm, y_val))\n\nl2_100.fit(x_train_sc, y_train.values.ravel())\nprint(l2_100.score(x_val_sc, y_val))\nl2_10.fit(x_train_mm, y_train.values.ravel()) #0.8571428571428571\nprint(l2_10.score(x_val_mm, y_val))\nl2_1.fit(x_train_mm, y_train.values.ravel())\nprint(l2_1.score(x_val_mm, y_val))\nl2_01.fit(x_train_mm, y_train.values.ravel())\nprint(l2_01.score(x_val_mm, y_val))\n\n# l1_100.fit(x_train_sc, y_train.values.ravel())\n# print(l1_100.score(x_val_sc, y_val))\n# l1_10.fit(x_train_mm, y_train.values.ravel()) #0.8571428571428571\n# print(l1_10.score(x_val_mm, y_val))\n# l1_1.fit(x_train_mm, y_train.values.ravel())\n# print(l1_1.score(x_val_mm, y_val))\n# l1_01.fit(x_train_mm, y_train.values.ravel())\n# print(l1_01.score(x_val_mm, y_val))","metadata":{"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"0.8181818181818182\n0.6363636363636364\n0.8181818181818182\n0.8181818181818182\n0.7272727272727273\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# submit","metadata":{}},{"cell_type":"code","source":"# # 1. 표준화 - 0.65~로 오름\n# x_data_sc = sc.fit_transform(x_data)\n# test_data_sc = sc.transform(test_data)\n\n# lg.fit(x_data_sc, y_data.values.ravel())\n# prediction = lg.predict(test_data_sc)\n# print(prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # 2. 표준화 - 0.65~로 같음\n# x_data_sc = sc.fit_transform(x_data)\n# test_data_sc = sc.transform(test_data)\n\n# l1_1.fit(x_data_sc, y_data.values.ravel())\n# prediction = l1_1.predict(test_data_sc)\n# print(prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # 3. 정규화\n# x_data_mm = mm.fit_transform(x_data)\n# test_data_mm = mm.transform(test_data)\n\n# l2_10.fit(x_data_mm, y_data.values.ravel())\n# prediction = l2_10.predict(test_data_mm)\n# print(prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # 3. 정규화\n# x_data_mm = mm.fit_transform(x_data)\n# test_data_mm = mm.transform(test_data)\n\n# l1_10.fit(x_data_mm, y_data.values.ravel())\n# prediction = l1_10.predict(test_data_mm)\n# print(prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # 4. 표준화 - 0.65~로 같음\n# x_data_sc = sc.fit_transform(x_data)\n# test_data_sc = sc.transform(test_data)\n\n# l2_1.fit(x_data_sc, y_data.values.ravel())\n# prediction = l2_1.predict(test_data_sc)\n# print(prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # 2. 표준화 - 0.65~로 같음\n# x_data_sc = sc.fit_transform(x_data)\n# test_data_sc = sc.transform(test_data)\n\n# l2_01.fit(x_data_sc, y_data.values.ravel())\n# prediction = l2_01.predict(test_data_sc)\n# print(prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# oversampling한 것\n\nlg.fit(x_sm, y_sm)\nprediction = lg.predict(test_data)\nprint(prediction)","metadata":{"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"[1 1 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 0]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  return f(*args, **kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"# # 표준화 - oversampling\n# x_sm_sc = sc.fit_transform(x_sm)\n# test_data_sc = sc.transform(test_data)\n\n# lg.fit(x_sm_sc, y_sm)\n# prediction = lg.predict(test_data_sc)\n# print(prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit['label'] = prediction","metadata":{"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"submit.to_csv('submit.csv', header = True, index = False)","metadata":{"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
